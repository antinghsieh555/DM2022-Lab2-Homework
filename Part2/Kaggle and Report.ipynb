{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Part 2\n","\n","(## Part 3 Report is as at below)"]},{"cell_type":"markdown","metadata":{},"source":["### Student Information\n","Name: Ë¨ùÂÆâ‰∫≠\n","\n","Student ID:110065516\n","\n","GitHub ID:antinghsieh555\n","\n","Kaggle name: AnterX\n","\n","Kaggle private scoreboard snapshot:\n","\n","[Snapshot](output/screenshot.png)"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-11-27T17:45:34.603629Z","iopub.status.busy":"2022-11-27T17:45:34.602360Z","iopub.status.idle":"2022-11-27T17:45:34.614597Z","shell.execute_reply":"2022-11-27T17:45:34.613650Z","shell.execute_reply.started":"2022-11-27T17:45:34.603559Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/dm2022-isa5810-lab2-homework/tweets_DM.json\n","/kaggle/input/dm2022-isa5810-lab2-homework/sampleSubmission.csv\n","/kaggle/input/dm2022-isa5810-lab2-homework/data_identification.csv\n","/kaggle/input/dm2022-isa5810-lab2-homework/emotion.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["# Data Preprocess\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-11-27T17:45:34.617586Z","iopub.status.busy":"2022-11-27T17:45:34.616521Z","iopub.status.idle":"2022-11-27T17:46:07.488443Z","shell.execute_reply":"2022-11-27T17:46:07.487268Z","shell.execute_reply.started":"2022-11-27T17:45:34.617531Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Start\n","         tweet_id                                               text  \\\n","0        0x376b20  People who post \"add me on #Snapchat\" must be ...   \n","1        0x2d5350  @brianklaas As we see, Trump is dangerous to #...   \n","2        0x28b412  Confident of your obedience, I write to you, k...   \n","3        0x1cd5b0                Now ISSA is stalking Tasha üòÇüòÇüòÇ <LH>   \n","4        0x2de201  \"Trust is not the same as faith. A friend is s...   \n","...           ...                                                ...   \n","1867530  0x316b80  When you buy the last 2 tickets remaining for ...   \n","1867531  0x29d0cb  I swear all this hard work gone pay off one da...   \n","1867532  0x2a6a4f  @Parcel2Go no card left when I wasn't in so I ...   \n","1867533  0x24faed  Ah, corporate life, where you can date <LH> us...   \n","1867534  0x34be8c             Blessed to be living #Sundayvibes <LH>   \n","\n","                                hashtags  \n","0                             [Snapchat]  \n","1          [freepress, TrumpLegacy, CNN]  \n","2                           [bibleverse]  \n","3                                     []  \n","4                                     []  \n","...                                  ...  \n","1867530  [mixedfeeling, butimTHATperson]  \n","1867531                               []  \n","1867532                               []  \n","1867533                               []  \n","1867534                    [Sundayvibes]  \n","\n","[1867535 rows x 3 columns]\n","Finish!\n"]}],"source":["# Read data\n","import numpy as np\n","import pandas as pd \n","import json \n","import os\n","\n","path ='/kaggle/input/dm2022-isa5810-lab2-homework/'\n","\n","data_id = pd.read_csv(path + \"data_identification.csv\") #1867535\n","emotion = pd.read_csv(path + \"emotion.csv\") #1455563\n","sampleSubmission = pd.read_csv(path + \"sampleSubmission.csv\") #411972\n","\n","print('Start')\n","tweets = []\n","for line in open(path + 'tweets_DM.json', 'r'):\n","    line_ = json.loads(line)\n","    tweets.append(line_)\n","\n","\n","df = pd.DataFrame(columns=['tweet_id','text', 'hashtags'])\n","df[\"tweet_id\"] = [tweet[\"_source\"][\"tweet\"][\"tweet_id\"] for tweet in tweets]\n","df[\"text\"] = [tweet[\"_source\"][\"tweet\"][\"text\"] for tweet in tweets]\n","df[\"hashtags\"] = [tweet[\"_source\"][\"tweet\"][\"hashtags\"] for tweet in tweets]\n","print(df)\n","print('Finish!')"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-11-27T17:46:07.490586Z","iopub.status.busy":"2022-11-27T17:46:07.490211Z","iopub.status.idle":"2022-11-27T17:46:14.320893Z","shell.execute_reply":"2022-11-27T17:46:14.319940Z","shell.execute_reply.started":"2022-11-27T17:46:07.490535Z"},"trusted":true},"outputs":[],"source":["df.to_csv('/kaggle/working/tweets_DM.csv', sep='\\t', encoding='utf-8')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-11-27T17:46:14.323934Z","iopub.status.busy":"2022-11-27T17:46:14.323521Z","iopub.status.idle":"2022-11-27T17:46:19.538885Z","shell.execute_reply":"2022-11-27T17:46:19.537650Z","shell.execute_reply.started":"2022-11-27T17:46:14.323896Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct Train Shape =  1455563\n"]}],"source":["# Split train data\n","train_df = pd.merge(data_id,emotion)\n","train_df = pd.merge(train_df,df)\n","\n","if (train_df.shape[0] == data_id.loc[data_id['identification'] == 'train'].shape[0]):\n","    print('Correct Train Shape = ', train_df.shape[0])\n","else: print('Wrong Train Shape!')\n","train_df[\"emotion_code\"] = train_df.emotion.map({\"anger\":0, \"anticipation\":1, \"disgust\":2, \"fear\":3, \"sadness\":4, \"surprise\":5, \"trust\":6, \"joy\":7})\n","\n","# train_df"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-11-27T17:46:19.541142Z","iopub.status.busy":"2022-11-27T17:46:19.540713Z","iopub.status.idle":"2022-11-27T17:46:20.286212Z","shell.execute_reply":"2022-11-27T17:46:20.285234Z","shell.execute_reply.started":"2022-11-27T17:46:19.541101Z"},"trusted":true},"outputs":[],"source":["val_df = train_df.sample(frac=0.2)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-11-27T17:46:20.288084Z","iopub.status.busy":"2022-11-27T17:46:20.287689Z","iopub.status.idle":"2022-11-27T17:46:22.911552Z","shell.execute_reply":"2022-11-27T17:46:22.910620Z","shell.execute_reply.started":"2022-11-27T17:46:20.288046Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct Test Shape =  411972\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_id</th>\n","      <th>emotion</th>\n","      <th>identification</th>\n","      <th>text</th>\n","      <th>hashtags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0x2c7743</td>\n","      <td>surprise</td>\n","      <td>test</td>\n","      <td>When your friends offer to bring you food üò≠üíò #...</td>\n","      <td>[loyal, real]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0x2c1eed</td>\n","      <td>surprise</td>\n","      <td>test</td>\n","      <td>I've never let any money problems stop me.. I ...</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0x2826ea</td>\n","      <td>surprise</td>\n","      <td>test</td>\n","      <td>@KurtSchlichter Being a Hobby Historian Chelse...</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0x356d9a</td>\n","      <td>surprise</td>\n","      <td>test</td>\n","      <td>#Cannabis¬†offers a natural alternative treatme...</td>\n","      <td>[Cannabis, Marijuana, Weed, Hemp, Medicine, Le...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0x20fd95</td>\n","      <td>surprise</td>\n","      <td>test</td>\n","      <td>Last Friday off before school starts. I'm read...</td>\n","      <td>[FridayFeeling]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>411967</th>\n","      <td>0x351857</td>\n","      <td>surprise</td>\n","      <td>test</td>\n","      <td>Rahul Gandhi didn't even talk about Himachal P...</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>411968</th>\n","      <td>0x2c028e</td>\n","      <td>surprise</td>\n","      <td>test</td>\n","      <td>I'm ok with fixing a PC for someone, but not w...</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>411969</th>\n","      <td>0x1f2430</td>\n","      <td>surprise</td>\n","      <td>test</td>\n","      <td>@brutofficiel I cannot believe this is happeni...</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>411970</th>\n","      <td>0x2be24e</td>\n","      <td>surprise</td>\n","      <td>test</td>\n","      <td>I had Ecuadorian food and Thai food today &lt;LH&gt;</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>411971</th>\n","      <td>0x35802a</td>\n","      <td>surprise</td>\n","      <td>test</td>\n","      <td>At the point in my life where I am asking for ...</td>\n","      <td>[]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>411972 rows √ó 5 columns</p>\n","</div>"],"text/plain":["        tweet_id   emotion identification  \\\n","0       0x2c7743  surprise           test   \n","1       0x2c1eed  surprise           test   \n","2       0x2826ea  surprise           test   \n","3       0x356d9a  surprise           test   \n","4       0x20fd95  surprise           test   \n","...          ...       ...            ...   \n","411967  0x351857  surprise           test   \n","411968  0x2c028e  surprise           test   \n","411969  0x1f2430  surprise           test   \n","411970  0x2be24e  surprise           test   \n","411971  0x35802a  surprise           test   \n","\n","                                                     text  \\\n","0       When your friends offer to bring you food üò≠üíò #...   \n","1       I've never let any money problems stop me.. I ...   \n","2       @KurtSchlichter Being a Hobby Historian Chelse...   \n","3       #Cannabis¬†offers a natural alternative treatme...   \n","4       Last Friday off before school starts. I'm read...   \n","...                                                   ...   \n","411967  Rahul Gandhi didn't even talk about Himachal P...   \n","411968  I'm ok with fixing a PC for someone, but not w...   \n","411969  @brutofficiel I cannot believe this is happeni...   \n","411970     I had Ecuadorian food and Thai food today <LH>   \n","411971  At the point in my life where I am asking for ...   \n","\n","                                                 hashtags  \n","0                                           [loyal, real]  \n","1                                                      []  \n","2                                                      []  \n","3       [Cannabis, Marijuana, Weed, Hemp, Medicine, Le...  \n","4                                         [FridayFeeling]  \n","...                                                   ...  \n","411967                                                 []  \n","411968                                                 []  \n","411969                                                 []  \n","411970                                                 []  \n","411971                                                 []  \n","\n","[411972 rows x 5 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Split test data\n","test_df = data_id.loc[data_id['identification'] == 'test']\n","submit_temp = sampleSubmission.rename(columns={'id':'tweet_id'})\n","submit_temp = pd.merge(submit_temp, test_df)\n","test_df = pd.merge(submit_temp, df)\n","\n","if (test_df.shape[0] == data_id.loc[data_id['identification'] == 'test'].shape[0]):\n","    print('Correct Test Shape = ', test_df.shape[0])\n","else: print('Wrong Test Shape!')\n","test_df\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-11-27T17:46:22.913949Z","iopub.status.busy":"2022-11-27T17:46:22.912855Z","iopub.status.idle":"2022-11-27T17:46:30.544672Z","shell.execute_reply":"2022-11-27T17:46:30.543633Z","shell.execute_reply.started":"2022-11-27T17:46:22.913906Z"},"trusted":true},"outputs":[],"source":["train_df.to_csv('/kaggle/working/train_data.csv', index=False)\n","test_df.to_csv('/kaggle/working/test_data.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Read Train and Test Data\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-11-27T17:46:30.546599Z","iopub.status.busy":"2022-11-27T17:46:30.546205Z","iopub.status.idle":"2022-11-27T17:46:36.865550Z","shell.execute_reply":"2022-11-27T17:46:36.864527Z","shell.execute_reply.started":"2022-11-27T17:46:30.546546Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd \n","train = pd.read_csv('/kaggle/working/train_data.csv',\n","                    lineterminator='\\n')\n","test = pd.read_csv('/kaggle/working/test_data.csv',\n","                   lineterminator='\\n')\n","train['text'] = train['text'].apply(lambda x: x.lower())\n","test['text'] = test['text'].apply(lambda x: x.lower())"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-11-27T17:47:38.178350Z","iopub.status.busy":"2022-11-27T17:47:38.177544Z","iopub.status.idle":"2022-11-27T17:47:57.912129Z","shell.execute_reply":"2022-11-27T17:47:57.911054Z","shell.execute_reply.started":"2022-11-27T17:47:38.178315Z"},"trusted":true},"outputs":[],"source":["import re\n","emailsRegex = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n","userMentionsRegex = re.compile(r'(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)')\n","urlsRegex = re.compile('r(f|ht)(tp)(s?)(://)(.*)[.|/][^ ]+')\n","numsRegex = re.compile(r\"\\b\\d+\\b\")\n","\n","texts = train['text']\n","\n","texts = texts.apply(lambda a:a.replace(\"<LH>\",\"\"))\n","texts = texts.apply(lambda a:userMentionsRegex.sub(' USER',a))\n","texts = texts.apply(lambda a:emailsRegex.sub(' EMAIL',a))\n","texts = texts.apply(lambda a:urlsRegex.sub(' URL',a))\n","texts = texts.apply(lambda a:numsRegex.sub(' NUM',a))"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-11-27T17:49:46.855731Z","iopub.status.busy":"2022-11-27T17:49:46.855346Z","iopub.status.idle":"2022-11-27T17:49:46.935436Z","shell.execute_reply":"2022-11-27T17:49:46.934474Z","shell.execute_reply.started":"2022-11-27T17:49:46.855700Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_id</th>\n","      <th>identification</th>\n","      <th>emotion</th>\n","      <th>text</th>\n","      <th>hashtags</th>\n","      <th>emotion_code</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0x29e452</td>\n","      <td>train</td>\n","      <td>joy</td>\n","      <td>huge respectüñí  USER talking about losing his d...</td>\n","      <td>[]</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0x2b3819</td>\n","      <td>train</td>\n","      <td>joy</td>\n","      <td>yoooo we hit all our monthly goals with the ne...</td>\n","      <td>['spateradio', 'app']</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0x2a2acc</td>\n","      <td>train</td>\n","      <td>trust</td>\n","      <td>USER  USER_bch  USER  USER well done team üåü &lt;...</td>\n","      <td>[]</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0x2a8830</td>\n","      <td>train</td>\n","      <td>joy</td>\n","      <td>come join  USER on #pubg while he strives for ...</td>\n","      <td>['PUBG', 'GamersUnite', 'twitch', 'BeHealthy',...</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0x20b21d</td>\n","      <td>train</td>\n","      <td>anticipation</td>\n","      <td>USER blessings!my #strength little. my #bones...</td>\n","      <td>['strength', 'bones', 'God']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1455558</th>\n","      <td>0x227e25</td>\n","      <td>train</td>\n","      <td>disgust</td>\n","      <td>USER such an inspirational talented person, w...</td>\n","      <td>['rip']</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1455559</th>\n","      <td>0x293813</td>\n","      <td>train</td>\n","      <td>sadness</td>\n","      <td>and still #libtards won't get off the guy's ba...</td>\n","      <td>['libtards', 'Hillary', 'lost', 'sad', 'growup...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1455560</th>\n","      <td>0x1e1a7e</td>\n","      <td>train</td>\n","      <td>joy</td>\n","      <td>when you sow #seeds of service or hospitality ...</td>\n","      <td>['seeds', 'Joy', 'GLTChurch']</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>1455561</th>\n","      <td>0x2156a5</td>\n","      <td>train</td>\n","      <td>trust</td>\n","      <td>USER will you be displaying some &lt;lh&gt; wares  ...</td>\n","      <td>[]</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1455562</th>\n","      <td>0x2bb9d2</td>\n","      <td>train</td>\n","      <td>trust</td>\n","      <td>lord, i &lt;lh&gt; in you.</td>\n","      <td>[]</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1455563 rows √ó 6 columns</p>\n","</div>"],"text/plain":["         tweet_id identification       emotion  \\\n","0        0x29e452          train           joy   \n","1        0x2b3819          train           joy   \n","2        0x2a2acc          train         trust   \n","3        0x2a8830          train           joy   \n","4        0x20b21d          train  anticipation   \n","...           ...            ...           ...   \n","1455558  0x227e25          train       disgust   \n","1455559  0x293813          train       sadness   \n","1455560  0x1e1a7e          train           joy   \n","1455561  0x2156a5          train         trust   \n","1455562  0x2bb9d2          train         trust   \n","\n","                                                      text  \\\n","0        huge respectüñí  USER talking about losing his d...   \n","1        yoooo we hit all our monthly goals with the ne...   \n","2         USER  USER_bch  USER  USER well done team üåü <...   \n","3        come join  USER on #pubg while he strives for ...   \n","4         USER blessings!my #strength little. my #bones...   \n","...                                                    ...   \n","1455558   USER such an inspirational talented person, w...   \n","1455559  and still #libtards won't get off the guy's ba...   \n","1455560  when you sow #seeds of service or hospitality ...   \n","1455561   USER will you be displaying some <lh> wares  ...   \n","1455562                               lord, i <lh> in you.   \n","\n","                                                  hashtags  emotion_code  \n","0                                                       []             7  \n","1                                    ['spateradio', 'app']             7  \n","2                                                       []             6  \n","3        ['PUBG', 'GamersUnite', 'twitch', 'BeHealthy',...             7  \n","4                             ['strength', 'bones', 'God']             1  \n","...                                                    ...           ...  \n","1455558                                            ['rip']             2  \n","1455559  ['libtards', 'Hillary', 'lost', 'sad', 'growup...             4  \n","1455560                      ['seeds', 'Joy', 'GLTChurch']             7  \n","1455561                                                 []             6  \n","1455562                                                 []             6  \n","\n","[1455563 rows x 6 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["train['text'] = texts"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-11-27T17:50:32.525408Z","iopub.status.busy":"2022-11-27T17:50:32.525038Z","iopub.status.idle":"2022-11-27T17:50:39.614514Z","shell.execute_reply":"2022-11-27T17:50:39.613107Z","shell.execute_reply.started":"2022-11-27T17:50:32.525378Z"},"trusted":true},"outputs":[],"source":["train_df.to_csv('/kaggle/working/train_data.csv', index=False)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-11-27T17:51:31.350382Z","iopub.status.busy":"2022-11-27T17:51:31.349471Z","iopub.status.idle":"2022-11-27T17:51:38.544237Z","shell.execute_reply":"2022-11-27T17:51:38.543121Z","shell.execute_reply.started":"2022-11-27T17:51:31.350334Z"},"trusted":true},"outputs":[],"source":["texts = test['text']\n","\n","texts = texts.apply(lambda a:a.replace(\"<LH>\",\"\"))\n","texts = texts.apply(lambda a:userMentionsRegex.sub(' USER',a))\n","texts = texts.apply(lambda a:emailsRegex.sub(' EMAIL',a))\n","texts = texts.apply(lambda a:urlsRegex.sub(' URL',a))\n","texts = texts.apply(lambda a:numsRegex.sub(' NUM',a))"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-11-27T17:51:45.369186Z","iopub.status.busy":"2022-11-27T17:51:45.368817Z","iopub.status.idle":"2022-11-27T17:51:45.404322Z","shell.execute_reply":"2022-11-27T17:51:45.403386Z","shell.execute_reply.started":"2022-11-27T17:51:45.369156Z"},"trusted":true},"outputs":[],"source":["test['text'] = texts"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-11-27T17:52:04.865770Z","iopub.status.busy":"2022-11-27T17:52:04.865392Z","iopub.status.idle":"2022-11-27T17:52:06.784974Z","shell.execute_reply":"2022-11-27T17:52:06.783454Z","shell.execute_reply.started":"2022-11-27T17:52:04.865738Z"},"trusted":true},"outputs":[],"source":["test_df.to_csv('/kaggle/working/test_data.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Part 3"]},{"cell_type":"markdown","metadata":{},"source":["### 1. Input Data Preprocessing\n","\n","First, I read the data from \"tweets_DM.json\".\n","Next, I merged \"tweet_id\", \"text\" and \"hashtags\" from \"data_identification.csv\" and \"tweets_DM.json\".\n","\n","Then, concatenated the dataframe with the emotion label."]},{"cell_type":"markdown","metadata":{},"source":["### 2.Text Preprocessing\n","\n","After processing all the input data, the next thing is to process the text data.\n","\n","1. Delete \"LH\" token in the text\n","2. Convert all text into lowercase\n","3. Replace @user token with USER token.\n"," e.g.@ERIC ===> USER\n","4. Replace url token with URL token.\n","5. Replace number of times token with NUM token.\n","e.g.25 times ===> NUM times"]},{"cell_type":"markdown","metadata":{},"source":["### 3. Train BERT model with training data\n","#### 3-1 : Load pre-train word embeddings model\n","In this method, I used pre-trained BERT-based word embedding vectors.\n","\n","#### 3-2 : Input data preparation\n","\n","1. Split the data into training set and testing set (test_size=0.2).\n","2. Use keras Tokenizer to tokenize text.\n","3. Use keras pad_sequences to pad the text (maxlen=50).\n","4. Utilize keras.utils.to_categorical for emotion label.(8 categoricals total)\n","5. Create word embedding matrix with pre-trained embeddings.(BERT embedding)\n","\n","#### 3-3 : Build BERT model\n"]},{"cell_type":"markdown","metadata":{},"source":["### 4. Result"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
